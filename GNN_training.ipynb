{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD Knowledge Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.utils import add_remaining_self_loops, add_self_loops\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.nn import GCNConv, GCN2Conv, SAGEConv,GAE, VGAE\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path='./'\n",
    "#exp_id='v0'\n",
    "device='cuda:4'\n",
    "device_id=4 #'cpu' if CPU, device number if GPU\n",
    "embedding_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './AD_project/pre_process_data/'\n",
    "exp_id='exp1'\n",
    "le=pickle.load(open(data_path+'AD_LabelEncoder_'+exp_id+'_kh.pkl', 'rb'))\n",
    "edge_index=pickle.load(open(data_path+'AD_edge_index_'+exp_id+'_kh.pkl','rb'))\n",
    "edge_index=edge_index[edge_index.type!='AD_related_inf']\n",
    "node_feature_np=pickle.load(open(data_path+'AD_node_feature_'+exp_id+'_kh.pkl','rb'))\n",
    "node_class=pickle.load(open(data_path+'AD_gene_node_class_'+exp_id+'_kh.pkl','rb'))\n",
    "node_class_mask=pickle.load(open(data_path+'gene_mask_'+exp_id+'_kh.pkl','rb'))\n",
    "AD_gene_index=pickle.load(open(data_path+'ad_gene_index_'+exp_id+'_kh.pkl','rb'))\n",
    "non_AD_gene_index=pickle.load(open(data_path+'non_ad_gene_index_'+exp_id+'_kh.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_AD_gene_node,test_AD_gene_node=train_test_split(AD_gene_index,test_size=0.1)\n",
    "train_non_AD_gene_node,test_non_AD_gene_node=train_test_split(AD_gene_index,test_size=0.1)\n",
    "train_node_index=train_AD_gene_node+train_non_AD_gene_node\n",
    "test_node_index=test_AD_gene_node+test_non_AD_gene_node\n",
    "train_node_edge_index=edge_index[(edge_index.node1.isin(train_node_index))|(edge_index.node2.isin(train_node_index))]\n",
    "test_node_edge_index=edge_index[(edge_index.node1.isin(test_node_index))|(edge_index.node2.isin(test_node_index))]\n",
    "all_node_edge_index=pd.concat([train_node_edge_index,test_node_edge_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature=torch.tensor(node_feature_np, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_dict={'gene-drug':0,'protein-protein':1, 'drug-phenotype':2,'gene-phenotype':3,'drug_pathway':4,'drug_sim':5,'AD_gene_pathway':6}#'mutation':3,\n",
    "\n",
    "edge_index['type']=edge_index['type'].apply(lambda x: edge_attr_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_edges(data, val_ratio=0.05, test_ratio=0.1):\n",
    "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
    "    into positive and negative train/val/test edges, and adds attributes of\n",
    "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
    "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
    "    to :attr:`data`.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The data object.\n",
    "        val_ratio (float, optional): The ratio of positive validation\n",
    "            edges. (default: :obj:`0.05`)\n",
    "        test_ratio (float, optional): The ratio of positive test\n",
    "            edges. (default: :obj:`0.1`)\n",
    "\n",
    "    :rtype: :class:`torch_geometric.data.Data`\n",
    "    \"\"\"\n",
    "\n",
    "    assert 'batch' not in data  # No batch-mode.\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    #data.edge_index = None\n",
    "    attr = data.edge_attr\n",
    "\n",
    "    # Return upper triangular portion.\n",
    "    #mask = row < col\n",
    "    #row, col = row[mask], col[mask]\n",
    "\n",
    "    n_v = int(math.floor(val_ratio * row.size(0)))\n",
    "    n_t = int(math.floor(test_ratio * row.size(0)))\n",
    "\n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    attr=attr[perm]\n",
    "\n",
    "    r, c = row[:n_v], col[:n_v]\n",
    "    data.val_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.val_pos_edge_attr = attr[:n_v]\n",
    "    \n",
    "    r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.test_post_edge_attr = attr[n_v:n_v + n_t]\n",
    "\n",
    "    r, c = row[n_v + n_t:], col[n_v + n_t:]\n",
    "    data.train_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.train_pos_edge_attr = attr[n_v+n_t:]\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
    "    perm = random.sample(range(neg_row.size(0)),\n",
    "                         min(n_v + n_t, neg_row.size(0)))\n",
    "    perm = torch.tensor(perm)\n",
    "    perm = perm.to(torch.long)\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    neg_adj_mask[neg_row, neg_col] = 0\n",
    "    data.train_neg_adj_mask = neg_adj_mask\n",
    "\n",
    "    row, col = neg_row[:n_v], neg_col[:n_v]\n",
    "    data.val_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_train_test_split_edges(data):\n",
    "    r\"\"\"Splits the edges of a :obj:`torch_geometric.data.Data` object\n",
    "    into positive and negative train/val/test edges, and adds attributes of\n",
    "    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,\n",
    "    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`\n",
    "    to :attr:`data`.\n",
    "\n",
    "    Args:\n",
    "        data (Data): The data object.\n",
    "        val_ratio (float, optional): The ratio of positive validation\n",
    "            edges. (default: :obj:`0.05`)\n",
    "        test_ratio (float, optional): The ratio of positive test\n",
    "            edges. (default: :obj:`0.1`)\n",
    "\n",
    "    :rtype: :class:`torch_geometric.data.Data`\n",
    "    \"\"\"\n",
    "\n",
    "    assert 'batch' not in data  # No batch-mode.\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    row, col = data.edge_index\n",
    "    #data.edge_index = None\n",
    "    attr = data.edge_attr\n",
    "\n",
    "    # Return upper triangular portion.\n",
    "    #mask = row < col\n",
    "    #row, col = row[mask], col[mask]\n",
    "\n",
    "    \n",
    "    # Positive edges.\n",
    "    perm = torch.randperm(row.size(0))\n",
    "    row, col = row[perm], col[perm]\n",
    "    attr=attr[perm]\n",
    "\n",
    "\n",
    "    r, c = row[:], col[:]\n",
    "    data.test_pos_edge_index = torch.stack([r, c], dim=0)\n",
    "    data.test_pos_edge_attr = attr[:]\n",
    "\n",
    "    # Negative edges.\n",
    "    neg_adj_mask = torch.ones(num_nodes, num_nodes, dtype=torch.uint8)\n",
    "    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)\n",
    "    neg_adj_mask[row, col] = 0\n",
    "\n",
    "    neg_row, neg_col = neg_adj_mask.nonzero().t()\n",
    "    perm = random.sample(range(neg_row.size(0)),len(row[:]))\n",
    "    perm = torch.tensor(perm)\n",
    "    perm = perm.to(torch.long)\n",
    "    neg_row, neg_col = neg_row[perm], neg_col[perm]\n",
    "\n",
    "    row, col = neg_row[:], neg_col[:]\n",
    "    data.test_neg_edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_VGAE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, isClassificationTask=False):\n",
    "        super(Encoder_VGAE, self).__init__()\n",
    "        self.isClassificationTask=isClassificationTask\n",
    "        self.conv_gene_drug = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_protein_protein = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_drug_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_gene_phenotype = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_drug_pathway = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_drug_sim = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.conv_AD_gene_pathway = SAGEConv(in_channels, 2*out_channels, )\n",
    "        self.bn = nn.BatchNorm1d(7*2*out_channels)\n",
    "        #variational encoder\n",
    "        self.conv_mu = SAGEConv(7*2*out_channels, out_channels, )\n",
    "        self.conv_logvar = SAGEConv(7*2*out_channels, out_channels,)\n",
    "\n",
    "    def forward(self,x,edge_index,edge_attr):\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        index_gene_drug=(edge_attr==0).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_drug=edge_index[:, index_gene_drug]\n",
    "        \n",
    "        index_protein_protein=(edge_attr==1).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_protein_protein=edge_index[:, index_protein_protein]\n",
    "        \n",
    "        index_drug_phenotype=(edge_attr==2).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_drug_phenotype=edge_index[:, index_drug_phenotype]\n",
    "        \n",
    "        index_gene_phenotype=(edge_attr==3).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_gene_phenotype=edge_index[:, index_gene_phenotype]\n",
    "        \n",
    "        index_drug_pathway=(edge_attr==4).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_drug_pathway=edge_index[:, index_drug_pathway]\n",
    "        \n",
    "        index_drug_sim=(edge_attr==5).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_drug_sim=edge_index[:, index_drug_sim]\n",
    "        \n",
    "        index_AD_gene_pathway=(edge_attr==6).nonzero().reshape(1,-1)[0]\n",
    "        edge_index_AD_gene_pathway=edge_index[:, index_AD_gene_pathway]\n",
    "        \n",
    "        x_gene_drug = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_drug)), p=0.5, training=self.training)\n",
    "        x_protein_protein = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_protein_protein)), p=0.5, training=self.training)\n",
    "        x_drug_phenotype = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_drug_phenotype)), p=0.5, training=self.training)\n",
    "        x_gene_phenotype = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_gene_phenotype)), p=0.5, training=self.training)\n",
    "        x_drug_pathway = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_drug_pathway)), p=0.5, training=self.training)\n",
    "        x_drug_sim = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_drug_sim)), p=0.5, training=self.training)\n",
    "        x_AD_gene_pathway = F.dropout(F.relu(self.conv_gene_drug(x,edge_index_AD_gene_pathway)), p=0.5, training=self.training)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x=self.bn(torch.cat([x_gene_drug,x_protein_protein,x_drug_phenotype,x_gene_phenotype,\n",
    "                             x_drug_pathway,x_drug_sim ,x_AD_gene_pathway   \n",
    "        ],dim=1))\n",
    "        \n",
    "        return self.conv_mu(x,edge_index), self.conv_logvar(x,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_auto_node(torch.nn.Module):\n",
    "    def __init__(self,num_features,hidden_channels,num_class,autoencoder):\n",
    "        super(GCN_auto_node, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_class)\n",
    "\n",
    "    def forward(self,x, edge_index,edge_attr, node_edge_index ):\n",
    "        z = self.autoencoder.encode(x, edge_index,edge_attr)\n",
    "        z_1 = self.conv1(z, node_edge_index)\n",
    "        z_1 = z_1.relu()\n",
    "        z_1 = F.dropout(z_1, p=0.5, training=self.training)\n",
    "        z_1 = self.conv2(z_1, edge_index)\n",
    "        return z_1,z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    class_inf,z=model(data.x, data.train_pos_edge_index,data.train_pos_edge_attr,data.node_train_edge)\n",
    "    class_inf=class_inf\n",
    "    node_criteria=nn.BCEWithLogitsLoss(weight=data.node_mask)\n",
    "    class_loss=node_criteria(class_inf.squeeze(), data.y.float())\n",
    "    \n",
    "    loss = model.autoencoder.recon_loss(z, data.train_pos_edge_index)\n",
    "    \n",
    "    loss_list= [loss,class_loss]\n",
    "    \n",
    "    #loss = loss+class_loss\n",
    "    #loss.backward()\n",
    "    #assert len(loss_list) == num_tasks\n",
    "    optimizer.pc_backward(loss_list)\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "\n",
    "def eval_fu(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_inf,z=model(data.x, data.train_pos_edge_index,data.train_pos_edge_attr,data.node_test_edge)\n",
    "        class_inf=class_inf.sigmoid()\n",
    "        edge_auc,edge_prc=model.autoencoder.test(z, data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "        class_inf=class_inf.squeeze().detach().cpu().numpy()\n",
    "        y=data.y.squeeze().detach().cpu().numpy()\n",
    "        class_mask=data.node_mask.squeeze().detach().cpu().numpy()\n",
    "        class_inf= class_inf[class_mask.nonzero()]\n",
    "        y=y[class_mask.nonzero()] \n",
    "        node_auc=metrics.roc_auc_score(y,class_inf)\n",
    "    return edge_auc,edge_prc,node_auc\n",
    "\n",
    "    \n",
    "def test(data,data_split):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_inf,z=model(data.x, data.train_pos_edge_index,data.train_pos_edge_attr,data.node_whole_edge)\n",
    "        class_inf=class_inf.sigmoid()\n",
    "        edge_auc,edge_prc=model.autoencoder.test(z, data_split.test_pos_edge_index, data_split.test_neg_edge_index)\n",
    "        class_inf=class_inf.squeeze().detach().cpu().numpy()\n",
    "        \n",
    "        y=data.y.squeeze().detach().cpu().numpy()\n",
    "        class_mask=data.node_mask.squeeze().detach().cpu().numpy()\n",
    "        class_inf= class_inf[class_mask.nonzero()]\n",
    "        y=y[class_mask.nonzero()] \n",
    "        node_auc=metrics.roc_auc_score(y,class_inf)\n",
    "        node_prc=metrics.average_precision_score(y,class_inf)\n",
    "    return edge_auc,edge_prc,node_auc,node_prc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic model only pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature=torch.tensor(node_feature_np, dtype=torch.float)\n",
    "edge_index_1=edge_index\n",
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)\n",
    "node_train_edge=torch.tensor(train_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_test_edge=torch.tensor(test_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_whole_edge=torch.tensor(all_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "\n",
    "node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "node_class_mask=torch.tensor(node_class_mask, dtype=torch.long)\n",
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)\n",
    "data = Data(x=node_feature,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            y=node_class\n",
    "           )\n",
    "data.node_train_edge=node_train_edge\n",
    "data.node_test_edge=node_test_edge\n",
    "data.node_whole_edge=node_whole_edge\n",
    "data.node_mask=node_class_mask\n",
    "data=data.to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole=train_test_split_edges(data)\n",
    "data_split=eval_train_test_split_edges(data)\n",
    "\n",
    "model=GCN_auto_node(embedding_size,64,1,VGAE((Encoder_VGAE(node_feature.shape[1], embedding_size)))).to(device_id)\n",
    "test(data_whole,data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_dict={'gene-drug':0,'protein-protein':1, 'drug-phenotype':2,'gene-phenotype':3,'drug_pathway':4,'drug_sim':5,'AD_gene_pathway':6}#'mutation':3,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_list=['gene-drug','protein-protein','drug-phenotype','gene-phenotype','drug_pathway','drug_sim','AD_gene_pathway']\n",
    "edge_type_ind=[0,1,2,3,4,5,6]\n",
    "for i in range(len(edge_type_ind)):\n",
    "    edge_index_1=edge_index[edge_index.type==edge_type_ind[i]]\n",
    "    edge=torch.tensor(edge_index_1[['node1', 'node2']].values, dtype=torch.long)\n",
    "    node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "    edge_attr=torch.tensor(edge_index_1['type'].values,dtype=torch.long)\n",
    "    data_split = Data(x=node_feature,\n",
    "                edge_index=edge.t().contiguous(),\n",
    "                edge_attr=edge_attr,\n",
    "                y=node_class\n",
    "               )\n",
    "    model=GCN_auto_node(embedding_size,64,1,VGAE((Encoder_VGAE(node_feature.shape[1], embedding_size)))).to(device_id)\n",
    "    data_split=eval_train_test_split_edges(data_split)\n",
    "    edge_auc,edge_prc,_,_=test(data_whole,data_split)\n",
    "    print('edge_type :{} edge_auc: {:.4f}, edge_prc: {:.4f}'.format(edge_type_list[i] ,edge_auc,edge_prc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, data_whole\n",
    "gc.collect()\n",
    "del data_split\n",
    "with torch.cuda.device(device):\n",
    "        torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model with random inition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature=nn.Embedding(len(le.classes_), 400)\n",
    "node_feature=node_feature.weight.data.uniform_(-1, 1)\n",
    "edge_index_1=edge_index\n",
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)\n",
    "node_train_edge=torch.tensor(train_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_test_edge=torch.tensor(test_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_whole_edge=torch.tensor(all_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "\n",
    "node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "node_class_mask=torch.tensor(node_class_mask, dtype=torch.long)\n",
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)\n",
    "data = Data(x=node_feature,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            y=node_class\n",
    "           )\n",
    "data.node_train_edge=node_train_edge\n",
    "data.node_test_edge=node_test_edge\n",
    "data.node_whole_edge=node_whole_edge\n",
    "data.node_mask=node_class_mask\n",
    "data=data.to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole=train_test_split_edges(data)\n",
    "data_split=eval_train_test_split_edges(data)\n",
    "\n",
    "model=GCN_auto_node(embedding_size,64,1,VGAE((Encoder_VGAE(node_feature.shape[1], embedding_size)))).to(device_id)\n",
    "learnable_params=model.parameters()\n",
    "optimizer = PCGrad(torch.optim.Adam(learnable_params)) \n",
    "#optimizer=torch.optim.Adam(learnable_params)\n",
    "for i in range(200):\n",
    "    train(data_whole)\n",
    "    edge_auc,edge_prc,node_auc=eval_fu(data_whole)\n",
    "    print('epoch :{} edge_auc: {:.4f}, edge_prc: {:.4f}, node_auc: {:.4f}'.format(i ,edge_auc,edge_prc,node_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(data_whole,data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_list=['gene-drug','protein-protein','drug-phenotype','gene-phenotype','drug_pathway','drug_sim','AD_gene_pathway']\n",
    "edge_type_ind=[0,1,2,3,4,5,6]\n",
    "for i in range(len(edge_type_ind)):\n",
    "    edge_index_1=edge_index[edge_index.type==edge_type_ind[i]]\n",
    "    edge=torch.tensor(edge_index_1[['node1', 'node2']].values, dtype=torch.long)\n",
    "    node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "    edge_attr=torch.tensor(edge_index_1['type'].values,dtype=torch.long)\n",
    "    data_split = Data(x=node_feature,\n",
    "                edge_index=edge.t().contiguous(),\n",
    "                edge_attr=edge_attr,\n",
    "                y=node_class\n",
    "               )\n",
    "    data_split=eval_train_test_split_edges(data_split)\n",
    "    edge_auc,edge_prc,_,_=test(data_whole,data_split)\n",
    "    print('edge_type :{} edge_auc: {:.4f}, edge_prc: {:.4f}'.format(edge_type_list[i] ,edge_auc,edge_prc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, data_whole\n",
    "gc.collect()\n",
    "del data_split\n",
    "with torch.cuda.device(device):\n",
    "        torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model with pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature=torch.tensor(node_feature_np, dtype=torch.float)\n",
    "edge_index_1=edge_index\n",
    "edge=torch.tensor(edge_index[['node1', 'node2']].values, dtype=torch.long)\n",
    "node_train_edge=torch.tensor(train_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_test_edge=torch.tensor(test_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "node_whole_edge=torch.tensor(all_node_edge_index[['node1', 'node2']].values.T, dtype=torch.long)\n",
    "\n",
    "node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "node_class_mask=torch.tensor(node_class_mask, dtype=torch.long)\n",
    "edge_attr=torch.tensor(edge_index['type'].values,dtype=torch.long)\n",
    "data = Data(x=node_feature,\n",
    "            edge_index=edge.t().contiguous(),\n",
    "            edge_attr=edge_attr,\n",
    "            y=node_class\n",
    "           )\n",
    "data.node_train_edge=node_train_edge\n",
    "data.node_test_edge=node_test_edge\n",
    "data.node_whole_edge=node_whole_edge\n",
    "data.node_mask=node_class_mask\n",
    "data=data.to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whole=train_test_split_edges(data)\n",
    "data_split=eval_train_test_split_edges(data)\n",
    "\n",
    "model=GCN_auto_node(embedding_size,64,1,VGAE((Encoder_VGAE(node_feature.shape[1], embedding_size)))).to(device_id)\n",
    "learnable_params=model.parameters()\n",
    "optimizer = PCGrad(torch.optim.Adam(learnable_params)) \n",
    "#optimizer=torch.optim.Adam(learnable_params)\n",
    "for i in range(200):\n",
    "    train(data_whole)\n",
    "    edge_auc,edge_prc,node_auc=eval_fu(data_whole)\n",
    "    print('epoch :{} edge_auc: {:.4f}, edge_prc: {:.4f}, node_auc: {:.4f}'.format(i ,edge_auc,edge_prc,node_auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(data_whole,data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type_list=['gene-drug','protein-protein','drug-phenotype','gene-phenotype','drug_pathway','drug_sim','AD_gene_pathway']\n",
    "edge_type_ind=[0,1,2,3,4,5,6]\n",
    "for i in range(len(edge_type_ind)):\n",
    "    edge_index_1=edge_index[edge_index.type==edge_type_ind[i]]\n",
    "    edge=torch.tensor(edge_index_1[['node1', 'node2']].values, dtype=torch.long)\n",
    "    node_class=torch.tensor(node_class, dtype=torch.long)\n",
    "    edge_attr=torch.tensor(edge_index_1['type'].values,dtype=torch.long)\n",
    "    data_split = Data(x=node_feature,\n",
    "                edge_index=edge.t().contiguous(),\n",
    "                edge_attr=edge_attr,\n",
    "                y=node_class\n",
    "               )\n",
    "    data_split=eval_train_test_split_edges(data_split)\n",
    "    edge_auc,edge_prc,_,_=test(data_whole,data_split)\n",
    "    print('edge_type :{} edge_auc: {:.4f}, edge_prc: {:.4f}'.format(edge_type_list[i] ,edge_auc,edge_prc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z=model.autoencoder.encode(data_whole.x, data_whole.edge_index, data_whole.edge_attr)\n",
    "z_np = z.squeeze().detach().cpu().numpy()\n",
    "z_np.shape\n",
    "pickle.dump(z_np, open('./AD_project/pre_process_data/drug_comb_node_embedding_comb_with_pretrain_kh.pkl', 'wb'))\n",
    "torch.save(model.state_dict(), './AD_project/pre_process_data/drug_comb_VAE_encoders_comb_withour_pretrain_kh.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, data_whole\n",
    "gc.collect()\n",
    "with torch.cuda.device(device):\n",
    "    torch.cuda.empty_cache()\n",
    "del data_split\n",
    "with torch.cuda.device(device):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
